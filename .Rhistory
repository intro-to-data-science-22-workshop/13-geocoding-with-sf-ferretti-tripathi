solution <- unlist(str_extract_all(secret, "[A-Z]"))
###
solution <- unlist(str_extract_all(secret, "[A-Z,!/.]"))
print(solution)
solution_string <- str_c(solution, collapse = "")
solution_final <- unlist(solution_string) %>% str_replace_all(., "\\.", " ")
print(solution_final)
print(solution)
print(solution_final)
get_files <- function(){
rvest_session <- session(url,
add_headers('From' = "lucreziaflavia.ferretti@hotmail.com",
'UserAgent' = R.Version()$version.string)) ##politeness
for (i in seq_along(scraped_text)) {
if (!file.exists(paste(articles_folder, scraped_text[i]))) {
tryCatch(
download.file(links_df[1:3], destfile = paste(articles_folder, scraped_text[i])),
error = function(e)
e
)
Sys.sleep(runif(1, 0, 1))##polite code (do not scrape at too high speed)
}
}
}
articles_folder1  <- get_files()
articles_folder1
return(articles_folder)
return(articles_folder1)
get_files <- function(){
rvest_session <- session(url,
add_headers('From' = "lucreziaflavia.ferretti@hotmail.com",
'UserAgent' = R.Version()$version.string)) ##politeness
for (i in seq_along(scraped_text)) {
if (!file.exists(paste(articles_folder, scraped_text[i]))) {
tryCatch(
download.file(links_df[i], destfile = paste(articles_folder, scraped_text[i])),
error = function(e)
e
)
Sys.sleep(runif(1, 0, 1))##polite code (do not scrape at too high speed)
}
}
return(articles_folder1)
}
articles_folder1  <- get_files()
get_files <- function(){
rvest_session <- session(url,
add_headers('From' = "lucreziaflavia.ferretti@hotmail.com",
'UserAgent' = R.Version()$version.string)) ##politeness
for (i in seq_along(scraped_text)) {
if (!file.exists(paste(articles_folder, scraped_text[i]))) {
tryCatch(
download.file(links_df[1:3], destfile = paste(articles_folder, scraped_text[i])),
error = function(e)
e
)
Sys.sleep(runif(1, 0, 1))##polite code (do not scrape at too high speed)
}
}
return(articles_folder1)
}
articles_folder1  <- get_files()
get_files <- function(){
rvest_session <- session(url,
add_headers('From' = "lucreziaflavia.ferretti@hotmail.com",
'UserAgent' = R.Version()$version.string)) ##politeness
for (i in seq_along(scraped_text)) {
if (!file.exists(paste(articles_folder, scraped_text[i]))) {
tryCatch(
download.file(links_df[i], destfile = paste(articles_folder, scraped_text[i])),
error = function(e)
e
)
Sys.sleep(runif(1, 0, 1))##polite code (do not scrape at too high speed)
}
}
return(articles_folder1)
}
articles_folder1  <- get_files()
articles_folder1  <- get_files()
articles_folder1
articles_folder <- paste0("~/Documents/GitHub/assignment-3-luflaferretti/Test/")
dir.create(articles_folder)
names <- c(1:length(links_df))
url <- "https://www.theguardian.com/international"
rvest_session <- session(url,
add_headers('From' = "lucreziaflavia.ferretti@hotmail.com",
'UserAgent' = R.Version()$version.string)) ##politeness
scraped_text <- rvest_session %>%
html_elements(xpath = "//div/h3/a//@href") %>%
html_text()
for (i in seq_along(scraped_text)) {
if (!file.exists(paste(articles_folder, scraped_text[i]))) {
tryCatch(
download.file(links_df[i], destfile = paste(articles_folder, scraped_text[i])),
error = function(e)
e
)
Sys.sleep(runif(1, 0, 1))##polite code (do not scrape at too high speed)
}
}
files <- list.files(articles_folder)
filesdf<- data.frame(files)
knitr::opts_chunk$set(echo = TRUE,
eval = TRUE,
error = FALSE,
message = FALSE,
warning = FALSE,
comment = NA)
##create wd:
articles_folder <- paste0("~/Documents/GitHub/assignment-3-luflaferretti/Test/")
dir.create(articles_folder)
names <- c(1:length(links_df))
ip_geolocated <- "24.33.233.189 Ohio 39.6062 -84.1695 55.206.140.56 Arizona 31.5552 -110.35 199.53.213.86 Zurich 47.3686 8.5391 85.114.48.220 Split-Dalmatia 43.0432 16.0875 182.79.240.83 Telangana 17.411 78.4487 98.65.172.56 Provence-Alpes-Cote d'Azur 43.2971 5.3668"
locations <- unlist(str_extract_all(ip_geolocated, "([a-zA-Z]+(-?[a-zA-Z]+)+) ?d?'?[a-zA-Z]*"))
locations <- str_trim(locations)
locations
ip_address <- unlist(str_extract_all(ip_geolocated,"\\b(?:(?:2(?:[0-4][0-9]|5[0-5])|[0-1]?[0-9]?[0-9])\\.){3}(?:(?:2([0-4][0-9]|5[0-5])|[0-1]?[0-9]?[0-9]))\\b"))
ip_address
coordinates <- unlist(str_extract_all(ip_geolocated,"\\d{2}.\\d{3,4} \\-?\\d{1,3}.\\d{2,4}"))
coordinates
geolocated_df <-data.frame(locations, ip_address, coordinates)
print(geolocated_df)
secret <- "clcopCow1zmstc0d87wnkig7OvdicpNuggvhryn92Gjuwczi8hqrfpRxs5Aj5dwpn0TanwoUwisdij7Lj8kpf03AT5Idr3coc0bt7yczjatOaootj55t3Nj3ne6c4Sfek.r1w1YwwojigOd6vrfUrbz2.2bkAnbhzgv4R9i05zEcrop.wAgnb.RqoE65fGEa1otfb7wXm24k.6t3sH9zqe5fy89n6Ed5t9kc4fR905gmc4Ogxo5nhk!gr"
solution <- unlist(str_extract_all(secret, "[A-Z,!/.]"))
print(solution)
solution_string <- str_c(solution, collapse = "")
solution_final <- unlist(solution_string) %>% str_replace_all(., "\\.", " ")
print(solution_final)
## get headlines with xpath:
guardian_url <- read_html("https://www.theguardian.com/international")
guardian_headlines1 <- html_elements(guardian_url, xpath = "//div/h3/a") %>%
html_text2()
##videos and podcast headlines are missing, so adding them:
guardian_headlines2<- html_elements(guardian_url, xpath= "//div/footer/ul/li/h4/a") %>%
html_text2()
guardian_headlines3 <- html_elements(guardian_url, xpath= "//div/div/div/div/a") %>%
html_text2()
##exclude the last 3 elements because they are not headlines:
guardian_headlines3a <- guardian_headlines3[1:2]
headlines_df<- c(guardian_headlines1, guardian_headlines2, guardian_headlines3a)
unique_headlines <- unique(headlines_df)
summary(unique_headlines)
##there are 115 unique headlines
##print 5 random headlines:
data.frame(unique_headlines)
sample(unique_headlines, 5)
data.frame(unique_headlines)
sample(unique_headlines, 5)
##remove punctuation:
headlines_df_words <- tibble(line = 1:length(unique_headlines), text = unique_headlines)
one_word_df <- headlines_df_words %>%
unnest_tokens(word, text)
data(stop_words)
tidy_one_word_df <- one_word_df %>%
anti_join(stop_words)
tidy_one_word_df %>%
count(word, sort = TRUE) %>%
head(5)
##get the links for all the headlines:
links1 <- html_elements(guardian_url, xpath = "//div/h3/a//@href") %>%
html_text2()
links2<- html_elements(guardian_url, xpath= "//div/footer/ul/li/h4/a//@href") %>%
html_text2()
links3 <- html_elements(guardian_url, xpath= "//div/div/div/div/a//@href") %>%
html_text2()
links3 <-  links3[1:2]
##create df:
links_df <- c(links1, links2, links3)
data.frame(links_df)
print(links_df)
summary(links_df)
##list the first 5 links:
links_df %>%
head (5)
articles_folder <- paste0("~/Documents/GitHub/assignment-3-luflaferretti/Test/")
dir.create(articles_folder)
names <- c(1:length(links_df))
url <- "https://www.theguardian.com/international"
rvest_session <- session(url,
add_headers('From' = "lucreziaflavia.ferretti@hotmail.com",
'UserAgent' = R.Version()$version.string)) ##politeness
scraped_text <- rvest_session %>%
html_elements(xpath = "//div/h3/a//@href") %>%
html_text()
for (i in seq_along(scraped_text)) {
if (!file.exists(paste(articles_folder, scraped_text[i]))) {
tryCatch(
download.file(links_df[i], destfile = paste(articles_folder, scraped_text[i])),
error = function(e)
e
)
Sys.sleep(runif(1, 0, 1))##polite code (do not scrape at too high speed)
}
}
files <- list.files(articles_folder)
filesdf<- data.frame(files)
filesdf %>%
mutate(files = as.numeric(files)) %>%
arrange(str_length(files), files) %>%
head(5)
length(files)
for (i in seq_along(links_df)) {
if (!file.exists(paste(articles_folder, names[i]))) {
tryCatch(
download.file(links_df[i], destfile = paste(articles_folder, names[i])),
error = function(e)
e
)
Sys.sleep(runif(1, 0, 1))##polite code (do not scrape at too high speed)
}
}
list_files <- list.files(articles_folder)
files_df<- data.frame(list_files)
##the files are in a messy order. arranging it:
files_df %>%
mutate(list_files = as.numeric(list_files)) %>%
arrange(str_length(list_files), list_files) %>%
head(5)
##total number of files:
length(list_files)
##the total number of files is 119
knitr::opts_chunk$set(echo = TRUE)
options(digits=2)
# save the built-in output hook
hook_output <- knitr::knit_hooks$get("output")
# set a new output hook to truncate text output
knitr::knit_hooks$set(output = function(x, options) {
if (!is.null(n <- options$out.lines)) {
x <- xfun::split_lines(x)
if (length(x) > n) {
# truncate the output
x <- c(head(x, n), "....\n")
}
x <- paste(x, collapse = "\n")
}
hook_output(x, options)
})
colorise <- function(x, color) {
if (knitr::is_latex_output()) {
sprintf("\\textcolor{%s}{%s}", color, x)
} else if (knitr::is_html_output()) {
sprintf("<span style='color: %s;'>%s</span>", color,
x)
} else x
}
pacman::p_load(kableExtra, tidyverse, broom, modelsummary, specr, janitor, modelr, wesanderson)
life_expec_dat <- read_csv("life_expectancy.csv") %>%
janitor::clean_names() %>%
mutate(developed = if_else(status == "Developed", 1, 0),
large = if_else(population > 50000000, 1, 0))
library(readr)
life_expectancy <- read_csv("Downloads/life_expectancy.csv")
View(life_expectancy)
life_expec_dat <- read_csv("life_expectancy.csv") %>%
janitor::clean_names() %>%
mutate(developed = if_else(status == "Developed", 1, 0),
large = if_else(population > 50000000, 1, 0))
life_expec_dat <- read_csv("life_expectancy.csv") %>%
janitor::clean_names() %>%
mutate(developed = if_else(status == "Developed", 1, 0),
large = if_else(population > 50000000, 1, 0))
head(life_expec_dat)
y ~ x1 + x2 # standard formula
y ~ . # include all other columns in data as x vars
y ~ x1 * x2 # Interaction terms
y ~ x + I(x^2) # higher order terms
formula_string <- paste("life_expectancy", "~ gdp")
formula_string
form <- as.formula(formula_string)# needs to be transformed to correct class
form
form <- lm(form, data = life_expec_dat)
reg <- lm(life_expectancy ~ gdp, data = life_expec_dat)
reg2 <- glm(life_expectancy ~ gdp, family = "gaussian", data = life_expec_dat)
form$coefficients == reg$coefficients
form$coefficients == reg2$coefficients
# function to include different y variables.
lm_fun_iter_y <-  function(dep_var) {
lm( as.formula(paste(dep_var, "~ gdp")), data = life_expec_dat)
}
# function to include different x variables.
lm_fun_iter_x <- function(indep_var) {
lm( as.formula(paste("life_expectancy ~", paste(indep_var, collapse = "+"))), data = life_expec_dat)
}
# create vector of variables to iterate over
vars <- life_expec_dat %>%
select(-c("life_expectancy", "country")) %>%
names()
# run a bivariate model for each column
biv_model_out <-  vars %>%
map(lm_fun_iter_x)
# create vector of variables to iterate over
vars <- life_expec_dat %>%
select(-c("life_expectancy", "country")) %>%
names()
# run a bivariate model for each column
biv_model_out <-  vars %>%
map(lm_fun_iter_x)
# run a bivariate model for each column
biv_model_out <-  vars %>%
map(lm_fun_iter_x)
biv_model_out <-  vars %>%
map(lm_fun_iter_x)
# create vector of variables to iterate over
vars <- life_expec_dat %>%
select(-c("life_expectancy", "country")) %>%
names()
lm_fun_iter_x <- function(indep_var) {
lm( as.formula(paste("life_expectancy ~", paste(indep_var, collapse = "+"))), data = life_expec_dat)## I use the collapse part to add an additional variable
}
# run a bivariate model for each column
biv_model_out <-  vars %>%
map(lm_fun_iter_x)
biv_model_out
biv_model_out_w_names <-  vars %>%
set_names() %>%
map(lm_fun_iter_x)
life_expec_dat <- read_csv("life_expectancy.csv") %>%
janitor::clean_names() %>%
mutate(developed = if_else(status == "Developed", 1, 0),
large = if_else(population > 50000000, 1, 0))
knitr:purl("lab 8 modeling.Rmd")
knitr::purl("lab 8 modeling.Rmd")
life_expec_dat <- read_csv("life_expectancy.csv") %>%
janitor::clean_names() %>%
mutate(developed = if_else(status == "Developed", 1, 0),
large = if_else(population > 50000000, 1, 0))
life_expec_dat <- read_csv("life_expectancy.csv") %>%
janitor::clean_names() %>%
mutate(developed = if_else(status == "Developed", 1, 0),
large = if_else(population > 50000000, 1, 0))
setwd("~/Downloads")
life_expec_dat <- read_csv("life_expectancy.csv") %>%
janitor::clean_names() %>%
mutate(developed = if_else(status == "Developed", 1, 0),
large = if_else(population > 50000000, 1, 0))
head(life_expec_dat)
formula_string <- paste("life_expectancy", "~ gdp")
formula_string
form <- as.formula(formula_string)# needs to be transformed to correct class
form
form <- lm(form, data = life_expec_dat)
reg <- lm(life_expectancy ~ gdp, data = life_expec_dat)
reg2 <- glm(life_expectancy ~ gdp, family = "gaussian", data = life_expec_dat)
form$coefficients == reg$coefficients
form$coefficients == reg2$coefficients
lm_fun_iter_y <-  function(dep_var) {
lm( as.formula(paste(dep_var, "~ gdp")), data = life_expec_dat)
}
# function to include different x variables.
lm_fun_iter_x <- function(indep_var) {
lm( as.formula(paste("life_expectancy ~", paste(indep_var, collapse = "+"))), data = life_expec_dat)## I use the collapse part to add an additional variable
}
vars <- life_expec_dat %>%
select(-c("life_expectancy", "country")) %>%
names()
# run a bivariate model for each column
biv_model_out <-  vars %>%
map(lm_fun_iter_x)
vars <- life_expec_dat %>%
select(-c("life_expectancy", "country")) %>%
names()
# run a bivariate model for each column
biv_model_out <-  vars %>%
map(lm_fun_iter_x)
install.packages("xaringan")
library(xaringan)
# figures formatting setup
options(htmltools.dir.version = FALSE)
library(knitr)
opts_chunk$set(
prompt = T,
fig.align="center", #fig.width=6, fig.height=4.5,
# out.width="748px", #out.length="520.75px",
dpi=300, #fig.path='Figs/',
cache=T, #echo=F, warning=F, message=F
engine.opts = list(bash = "-l")
)
## Next hook based on this SO answer: https://stackoverflow.com/a/39025054
knit_hooks$set(
prompt = function(before, options, envir) {
options(
prompt = if (options$engine %in% c('sh','bash')) '$ ' else 'R> ',
continue = if (options$engine %in% c('sh','bash')) '$ ' else '+ '
)
})
title: "Geocoding"
# figures formatting setup
options(htmltools.dir.version = FALSE)
library(knitr)
opts_chunk$set(
comment = "  ",
prompt = T,
fig.align="center", #fig.width=6, fig.height=4.5,
# out.width="748px", #out.length="520.75px",
dpi=300, #fig.path='Figs/',
cache=F, #echo=F, warning=F, message=F
engine.opts = list(bash = "-l")
)
## Next hook based on this SO answer: https://stackoverflow.com/a/39025054
knit_hooks$set(
prompt = function(before, options, envir) {
options(
prompt = if (options$engine %in% c('sh','bash')) '$ ' else 'R> ',
continue = if (options$engine %in% c('sh','bash')) '$ ' else '+ '
)
})
library(tidyverse)
library(nycflights13)
library(modelsummary)
library(kableExtra)
---
title: "Geocoding"
.pull-right[
<br>
.pull-right[
<br>
.pull-center[
<br>
devtools::install_github("hadley/emo")
library(emo)
xaringan::inf_mr()
nc = read_sf(system.file("gpkg/nc.gpkg", package="sf")))
(nc = read_sf(system.file("gpkg/nc.gpkg", package="sf")))
library(ggplot2)
ggplot() + geom_sf(data = nc, aes(fill = SID74))
addresses <- c("Platz der Republik 1, 11011 Berlin, Germany)
addresses <- c("Platz der Republik 1, 11011 Berlin, Germany)
addresses <- c(Platz der Republik 1, 11011 Berlin, Germany)
addresses <- c("Platz der Republik 1, 11011 Berlin, Germany")
addresses <- c("Platz der Republik 1, 11011 Berlin, Germany", Friedrichstrasse 180, 10117 Berlin, Germany)
geocoded_addresses <- geocode_OSM(addresses)
library(tmap)
install.packages("tmap")
library(tmap)
install.packages("tmap")
library(tmaptools)
install.packages("tmaptools")
install.packages("xml")
install.packages("XML")
library(tmap)
library(tmaptools)
library(XML)
geocoded_addresses <- geocode_OSM(addresses)
print(geocoded_addresses[,1:3])
print(geocoded_addresses[,1:2])
geocoded_addresses <- geocode_OSM(addresses)
print(geocoded_addresses[,1:2])
addresses <- c("Platz der Republik 1, 11011 Berlin, Germany", "Friedrichstrasse 180, 10117 Berlin, Germany")
geocoded_addresses <- geocode_OSM(addresses)
print(geocoded_addresses[,1:2])
geocoded_addresses <- geocode_OSM(addresses)
print(geocoded_addresses[,1:2])
addresses <- c("Platz der Republik 1, 11011 Berlin, Germany")
geocoded_addresses <- geocode_OSM(addresses)
print(geocoded_addresses)
addresses <- c("Platz der Republik 1, 11011 Berlin")
geocoded_addresses <- geocode_OSM(addresses)
print(geocoded_addresses)
addresses <- c("Platz der Republik 1, 11011 Berlin", " Friedrichstrasse 180, 11011 Berlin")
geocoded_addresses <- geocode_OSM(addresses)
print(geocoded_addresses)
geocoded_addresses <- geocode_OSM(addresses, as.data.frame = TRUE)
print(geocoded_addresses)
geocoded_addresses <- geocode_OSM(addresses, as.data.frame = TRUE)
print(geocoded_addresses)
xaringan:::inf_mr()
# figures formatting setup
options(htmltools.dir.version = FALSE)
library(knitr)
opts_chunk$set(
comment = "  ",
prompt = T,
fig.align="center", #fig.width=6, fig.height=4.5,
# out.width="748px", #out.length="520.75px",
dpi=300, #fig.path='Figs/',
cache=F, #echo=F, warning=F, message=F
engine.opts = list(bash = "-l")
)
## Next hook based on this SO answer: https://stackoverflow.com/a/39025054
knit_hooks$set(
prompt = function(before, options, envir) {
options(
prompt = if (options$engine %in% c('sh','bash')) '$ ' else 'R> ',
continue = if (options$engine %in% c('sh','bash')) '$ ' else '+ '
)
})
library(tidyverse)
library(modelsummary)
library(kableExtra)
library(XML)
library(tmaptools)
library(tmap)
library(c(sf, tmaptools, tmap, dplyr))
addresses1 <- c("492 Old Connecticut Path, Framingham, MA",
"250 Northern Ave., Boston, MA")
geocoded_addresses <- geocode_OSM(addresses1)
print(geocoded_addresses[,1:3])
addresses <- c("Platz der Republik 1, 11011 Berlin", " Friedrichstrasse 180, 11011 Berlin")
geocoded_addresses <- geocode_OSM(addresses, as.data.frame = TRUE)
print(geocoded_addresses)
Germany <- "https://www.arcgis.com/sharing/rest/content/items/ae25571c60d94ce5b7fcbf74e27c00e0/data"
germany <- "https://www.arcgis.com/sharing/rest/content/items/ae25571c60d94ce5b7fcbf74e27c00e0/data"
download.file(germany, destfile = "BRA.zip")
download.file(germany, destfile = "DEU.zip")
unzip("DEU.zip")
germany <- "https://biogeo.ucdavis.edu/data/diva/adm/DEU_adm.zip"
View(germany_shp)
# Download .zip
download.file(germanyfile, destfile = "DEU.zip")
sf::st_crs(germany)
sf::st_crs(germany_shp)
